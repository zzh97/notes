## 一、导论
### （1）课程涵盖的内容和理念
#### 1.什么是机器学习
最早的机器学习应用：垃圾邮件分辨  
传统的技术解决问题思路：编写规则，定义“垃圾邮件”，让计算机执行  
对于很多问题，规则很难定义  
规则在不断变化
#### 2.主要内容
* ①KNN
* ②线性回归
* ③多项式回归
* ④逻辑回归
* ⑤模型正则化
* ⑥PCA（降维）
* ⑦SVM
* ⑧决策树
* ⑨随机森林
* ⑩集成学习
* ⑪模型选择
* ⑫模型调整
#### 3.理念
深入理解算法基本原理  
实际使用算法解决真实场景的问题  
对不同算法进行对比试验  
对同一算法的不同参数进行对比试验  
对部分算法底层编写
### （2）课程所使用的主要技术栈
#### 1.技术栈
*  语言：Python3
*  框架：Scikit-learn
*  其他：numpy，matplotlib  
（上述皆可安装Anaconda）
*  IDE：Jupyter Notebook、PyCharm
#### 2.数据集
*  内置数据集或通过scikit-learn能下载的数据集
*  MNIST数据集
### （3）机器学习世界的数据
#### 1.数据集（data set）：数据整体
#### 2.样本（sample）：每一行数据
#### 3.特征（feature）：除最后一列的每一列
#### 4.标记（label）：最后一列
#### 5.特征空间（feature space）
分类任务本质就是在特征空间切分
### （4）机器学习的基本任务
#### 1.分类任务
* 二分类
* 多分类  
很多复杂的问题都可以转化为多分类任务  
一些算法只支持完成二分类的任务  
但是多分类任务可以转换成二分类任务  
有一些算法天然可以完成多分类任务
#### 2.回归任务
* 分类任务：label是一个类别
* 回归任务：label是连续的值  
有些算法只能解决分类问题  
有些算法只能解决回归问题  
有些算法既能解决分类问题，又能解决回归问题  
回归任务可以划分为分类任务（连续数值离散化）
#### 3.学习模型
输入->模型(函数)->输出
### （5）机器学习的算法分类
#### 1.监督学习：有label
K邻近、线性回归和多项式回归、逻辑回归、SVM、决策树和随机森林
#### 2.非监督学习：没有label
#### 意义：
（聚类分析）对数据进行降维处理（提高运行效率，便于可视化）；异常检测；特征提取和特征压缩
#### 3.半监督学习：一部分有lael，一部分没有
通常先用无监督学习手段对数据做处理，之后使用监督学习手段做模型的训练和预测
#### 4.增强学习：根据环境，采取行动，获得反馈，学习
### （6）机器学习的其他分类
#### 1.批量学习：大量训练集训练模型，测试集不训练
* 优点：简单
* 问题：如何适应环境变化
* 解决方案：定时重新批量学习
* 缺点：每天重新学习，每次学两天，额，呵呵哒
#### 2.在线学习：测试集也用于训练
* 优点：及时反映新的环境变化
* 问题：新的数据带来不好的变化
* 解决方案：需要加强对数据进行监控
* 其他：若批量学习数据量太大，可转为在线学习
#### 3.参数学习：先假设符合某函数，然后学习其参数
#### 4.非参数学习：不作假设（非参数不等于没参数）
### （7）一些思考
#### 1.算法 vs 数据
#### 2.奥卡姆的剃刀（简单的就是好的）
#### 3.所有算法的期望相同（没有免费的午餐定理）
## 二、初试
### （1）安装IDE
#### 1.安装Anaconda（略 ）
#### 2.安装Jupyter notebook
	conda install jupyter notebook
或者  
	pip install jupyter notebook
#### 3.启动Jupyter notebook
	jupyter notebook
注：New->python3打开编辑区，直接Ctrl+C就能关闭了
### （2）使用IDE
#### 1.命令
* ①运行：Cell->Run Cells
* ②向下插入一行：Insert->Insert Cell Below
* ③运行并向下插入一行：Cell->Run Cells and Insert Below
* ④运行并向下选择一行：Cell->Run Cells and Select Below
* ⑤设置快捷键：Help->Keyboard shortcuts  
①Ctrl+Enter ②B（向上是A，删除是DD） ③Alt+Enter ④Shift+Enter  
注：在View中控制视图（菜单栏、行数等），Tab自动补全  
将改行变成md语法：Cell->Cell Type->Makedown，快捷键M（code是Y）
#### 2.魔法命令
	# 相对路径
	%run xxx/yyy.py
	# 导入模块
	import xxx.yyy
	# 或者
	from xxx import yyy
	# 测试效率（一行）
	%timeit list = [i**2 for i in range(1000)]
	#测试效率（多行）
	%%timeit
	list = []
	for i in range(1000):
		list.append(i ** 2)
	#只测试一次
	%time list = [i**2 for i in range(1000)]
	#查看所有的魔法命令
	%lsmagic
注：timeit是多次测试，取其中3次最优
### （3）Numpy
#### 1.导入Numpy
	import numpy
或者  
	#相当于命了个名
	import numpy as np
#### 2.为什么要用Numpy
* List不要求数据类型相同
* Array不具有向量/矩阵的操作
#### 3.使用Numpy
	#查看Numpy的版本
	np.__version__
	#定义0-9
	npArr = np.array([i for i in range(10)])
	#查看数据类型
	npArr.dtype
####4.快速定义
	#定义[0., 0., ...]共10个（10维的零向量）
	np.zeros(10)
	#定义[0, 0, ...]（整数型）
	np.zeros(10, dtype = int)
	#定义10维的零矩阵
	np.zeros((3, 5))
	#定义10维的整数型零矩阵
	np.zeros(shape = (3, 5), dtype = int)
注：参数名可加可不加，如若加，则参数可变化位置
	
	#[1., 1., ...]共10个
	np.ones(10)
	#定义全是6（float）的3行5列的矩阵
	np.full(fill_value = 6.0, shape = (3, 5))
	#[0, 2, 4, ..., 18]定义[0, 20)步长为2
	np.arange(0, 20, 2)
	#[0, 2, 4, ..., 20]定义[0, 20]共11个的等距点
	np.linspace(0, 20, 11)
	#置5个[0, 10)中的随机整数
	np.random.randint(0, 10, size = 5)
	#置3行5列的[0, 10)中的随机小数
	np.random.random(0, 10, size = (3, 5))
	#置3行5列的，期望为0，方差为1，符合正态分布的小数
	np.random.normal(0, 1, (3, 5))
	#查看文档，会弹出小窗口
	np.random.normal?
	#直接打印，不弹窗口
	help(np.random.normal)
####4.Numpy的基本操作
	#定义n为一维数组，并转为二维记作x
	n = np.arange(15)
	x = n.reshape(3, 5)
	#返回x的维数
	x.ndim
	#返回x的格式
	x.shape
	#返回x的长度
	x.size
	#三种获取x中第1行第1列元素的方法（推荐第三个）
	x[0][0]
	x[(0, 0)]
	x[0, 0]
	#获取倒数第一个元素
	n[-1]
	#获取从0到5的元素
	n[0:5]
	n[:5]
	#获取从5到尾的元素
	n[5:]
	#获取元素，步长为2
	n[::2]
	#元素倒序
	n[::-1]
	#获取从第1行到第2行，从第1列到第3列
	x[:2, :3]
	#先获取第1行到第2行，再获取第1行到第3行
	x[:2][:3]
	#获取第1行
	x[0]
	x[0, :]
	#获取第1列
	x[:, 5]
	#矩阵反转
	x[::-1, ::-1]
	#创建子矩阵，子矩阵改变，父矩阵也会变
	subX = x[:2, :3]
	#子矩阵改变，父矩阵不变
	subX = x[:2, :3].copy()
	#转为3行5列
	n.reshape(3, 5)
	#转为5行若干列
	n.reshape(5, -1)
####5.合并与分割
合并

	x = np.array([1,2,3])
	y = np.array([4,5,6])
	#合并x向量与y向量1X6
	np.concatenate([x, y])
	A = np.array([1,2,3],[4,5,6])
	#合并矩阵A与自身4X3
	np.concatenata([A, A])
	#合并矩阵A与自身3X4（按列合并）
	np.concatenata([A, A], axis=1)
	#垂直方向合并
	np.vstack([A,x])
	#水平方向合并
	np.hstack([A,A])
分割

	x = np.arange(10)
	#x1=[0,3)，x2=[3,7), x3=[7,10)
	x1, x2, x3 = np.split(3, 7)
	#按行分割（vsplit）
	A1, A2 = np.split(A, [2])
	#按列分割（hsplit）
	A1, A2 = np.split(A, [2], axis=1)
	#增广矩阵变成系数矩阵+label
	X, y = np.hsplit(A, [-1])
	y[:, 0]

####5.矩阵运算
向量与向量运算

	#数乘
	A = np.array([1,2,3])
	2 * A
	#除2
	A / 2
	#整除2
	A // 2
	#加减
	A + 1
	#取余
	A % 2
	#三角函数
	np.sin(A)
	np.exp(A)
	#指数函数（两种方法）
	np.power(3, A)
	3 ** A
	#对数函数
	np.log2(A)
矩阵与矩阵运算
	B = np.array([[1,2,3],[4,5,6]])
	B + B
	#对应元素相乘（而非矩阵乘法）
	B * B
	#矩阵乘法
	B.dot(B)
	#矩阵转置
	B.T
向量与矩阵运算

	#相加（与矩阵的每一行做加法）
	A + B
	#相乘
	A.dot(B)
矩阵的逆

	np.linalg.inv(B)
	# 伪逆矩阵
	np.linalg.pinv(B)

###（3）数据可视化
###1.Matplotlib
	#一般只需要用到plt
	import matplotlib as mpl
	import matplotlib.pyplot as plt
	#建立x和sin(x)、cos(x)
	x = np.linspace(0, 10, 30)
	siny = np.sin(x)
	cosy = np.cos(x)
	#处理数据（折线图），并显示(每次show都会清空数据)
	plt.plot(x, siny)
	plt.plot(x, cosy)
	plt.show()
	#更改样式，颜色（可以用16进制码），--为虚线，:为点线（还有:-和-）
	plt.plot(x, siny, linestyle='--')
	plt.plot(x, cosy, color='red')
	plt.show()
	#更改x轴和y轴的范围
	plt.plot(x, siny, linestyle='--')
	plt.plot(x, cosy, color='red')
	plt.ylim(-2, 2)
	plt.xlim(-1, 11)
	plt.show()
	#xy一起更改，并加上标签
	plt.plot(x, siny, linestyle='--')
	plt.plot(x, cosy, color='red')
	plt.axis([-1, 11, -2, 2])
	plt.xlabel('x axis')
	plt.ylabel('y value')
	plt.show()
	#给线条加上标签（注意要legend），最后加上标题
	plt.plot(x, siny, label='sin(x)')
	plt.plot(x, cosy, color = 'red', label='cos(x)')
	plt.xlabel('x axis')
	plt.ylabel('y value')
	plt.legend()
	plt.title('Welcome to the ML')
	plt.show()
	#绘制散点图
	plt.scatter(x, siny)
	plt.show()
	#绘制两个
	plt.scatter(x, siny)
	plt.scatter(x, cosy, color='red')
	plt.show()
	#绘制正态分布的散点图，并设置alpha
	x = np.random.normal(0, 1, 1000)
	y = np.random.normal(0, 1, 1000)
	plt.scatter(x, y, alpha=0.5)
	plt.show()
####2.加载数据
	#导入数据集
	from sklearn import datasets
	#加载鸢尾花数据
	iris = datasets.load_iris()
	#查看内容
	iris.keys()
	#打印文档
	print(iris.DESCR)
	#查看数据及其格式
	iris.data
	iris.data.shape
	#查看特征
	iris.feature_names
	#查看标记及其格式与内容
	iris.target
	iris.target.shape
	iris.target_names
	#只取前两列（降维）
	X = iris.data[:, :2]
	X.shape
	#显示散点图
	plt.scatter(X[:, 0], X[:, 1])
	plt.show()
	#根据标记绘制颜色
	y = iris.target
	plt.scatter(X[y==0, 0], X[y==0, 1], color='red')
	plt.scatter(X[y==1, 0], X[y==1, 1], color='blue')
	plt.scatter(X[y==2, 0], X[y==2, 1], color='green')
	plt.show()
	#改变点的样式
	plt.scatter(X[y==0, 0], X[y==0, 1], color='red', marker='o')
	plt.scatter(X[y==1, 0], X[y==1, 1], color='blue', marker='+')
	plt.scatter(X[y==2, 0], X[y==2, 1], color='green', marker='x')
	plt.show()
	#用后两列来绘制
	X = iris.data[:, 2:]
	plt.scatter(X[y==0, 0], X[y==0, 1], color='red', marker='o')
	plt.scatter(X[y==1, 0], X[y==1, 1], color='blue', marker='+')
	plt.scatter(X[y==2, 0], X[y==2, 1], color='green', marker='x')
	plt.show()
###（4）kNN（k近邻）
####1.特点
* 思想极度简单
* 应用数学知识少
* 效果好（缺点？）
* 可以解释机器学习算法使用过程中的很多细节问题
* 更完整的刻画机器学习应用的流程
注：k近邻算法是非常特殊的，可以被认为是没有模型的算法，为了和其他算法统一，可以认为训练数据集就是模型本身
####2.代码
	#库和数据
	import numpy as np
	import matplotlib.pyplot as plt
	raw_data_X = [[3.393533211, 2.331273381],
	              [3.110073483, 1.781539638],
	              [1.343808831, 3.368360954],
	              [3.582294042, 4.679179110],
	              [2.280362439, 2.866990263],
	              [7.423436942, 4.696522875],
	              [5.745051997, 3.533989803],
	              [9.172168622, 2.511101045],
	              [7.792783481, 3.424088941],
	              [7.939820817, 0.791637231]]
	raw_data_y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
	#训练集
	X_train = np.array(raw_data_X)
	y_train = np.array(raw_data_y)
	#绘制特征空间
	plt.scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], color='g')
	plt.scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], color='r')
	plt.show()
	#新的特征点并绘制
	x = np.array([8.093607318, 3.365731514])
	plt.scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], color='g')
	plt.scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], color='r')
	plt.scatter(x[0], x[1], color='b')
	plt.show()
	#计算距离
	from math import sqrt
	distances = []
	for x_train in X_train:
	    d = sqrt(np.sum((x_train - x)**2))
	    distances.append(d)
	#或者用生成器
	distances = [sqrt(np.sum((x_train - x)**2))for x_train in X_train]
	#排序（升序）并返回索引
	nearest = np.argsort(distances)
	#选择6个最近的
	k = 6
	topK_y = [y_train[i] for i in nearest[:k]]
	#投票
	from collections import Counter
	votes = Counter(topK_y)
	#结果
	predict_y = votes.most_common(1)[0][0]
####3.封装kNN
	import numpy as np #矩阵
	import matplotlib.pyplot as plt #绘图
	from math import sqrt #计算
	from collections import Counter #统计
	
	def kNN(k, X_train, y_train, x):
	    #断言
	    assert 1 <= k <= X_train.shape[0], "k must be valid"
	    assert X_train.shape[0] == y_train.shape[0], \
	        "the size of X_train must equal to the size of y_train"
	    assert X_train.shape[1] == x.shape[0], \
	        "the feature number of x must be equal to X_train"
	    #计算距离并排序
	    distances = [sqrt(np.sum((x_train - x)**2))for x_train in X_train]
	    nearest = np.argsort(distances)
	    #寻找最近点
	    topK_y = [y_train[i] for i in nearest[:k]]
	    votes = Counter(topK_y)
	    #返回结果
	    return votes.most_common(1)[0][0]
在jupyter notebook里运行

	#库和数据
	import numpy as np
	import matplotlib.pyplot as plt
	raw_data_X = [[3.393533211, 2.331273381],
	              [3.110073483, 1.781539638],
	              [1.343808831, 3.368360954],
	              [3.582294042, 4.679179110],
	              [2.280362439, 2.866990263],
	              [7.423436942, 4.696522875],
	              [5.745051997, 3.533989803],
	              [9.172168622, 2.511101045],
	              [7.792783481, 3.424088941],
	              [7.939820817, 0.791637231]]
	raw_data_y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
	#训练集
	X_train = np.array(raw_data_X)
	y_train = np.array(raw_data_y)
	#新数据
	x = np.array([8.093607318, 3.365731514])
	#导入kNN
	%run D:/zzh/machieLearn/kNN.py
	#调用kNN
	predict_y = kNN(6, X_train, y_train, x)
	#打印结果
	predict_y
####4.使用scikit-learn中的kNN
	#库和数据
	import numpy as np
	import matplotlib.pyplot as plt
	raw_data_X = [[3.393533211, 2.331273381],
	              [3.110073483, 1.781539638],
	              [1.343808831, 3.368360954],
	              [3.582294042, 4.679179110],
	              [2.280362439, 2.866990263],
	              [7.423436942, 4.696522875],
	              [5.745051997, 3.533989803],
	              [9.172168622, 2.511101045],
	              [7.792783481, 3.424088941],
	              [7.939820817, 0.791637231]]
	raw_data_y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
	#训练集
	X_train = np.array(raw_data_X)
	y_train = np.array(raw_data_y)
	#新数据
	x = np.array([8.093607318, 3.365731514])
	#导入scikit-learn中的kNN
	from sklearn.neighbors import KNeighborsClassifier
	#初始化kNN（k=6）
	kNN_classifier = KNeighborsClassifier(n_neighbors = 6)
	#训练模型
	kNN_classifier.fit(X_train, y_train)
	#进行预测，因为x是一个向量，故会警告
	kNN_classifier.predict(x)
	#把x转为矩阵后，再进行预测
	X_predict = x.reshape(1, -1)
	kNN_classifier.predict(X_predict)
####5.像scikit-learn那样，封装kNN
	import numpy as np #矩阵
	import matplotlib.pyplot as plt #绘图
	from math import sqrt #计算
	from collections import Counter #统计
	
	class KNN:
	    #初始化kNN分类器
	    def __init__(self, k):
	        #k要不小于1
	        assert k >= 1, "k must be valid"
	        self.k = k
	        self._X_train = None
	        self._y_train = None
	    #训练分类器
	    def fit(self, X_train, y_train):
	        assert X_train.shape[0] == y_train.shape[0], \
	            "the size of X_train must equal to the size of y_train"
	        assert self.k <= X_train.shape[0], \
	            "the size of X_train must be at least k"
	        #kNN中数据本身就是模型
	        self._X_train = X_train
	        self._y_train = y_train
	        return self
	    #预测
	    def predict(self, X_predict):
	        #predict前，先fit
	        assert self._X_train is not None and self._y_train is not None, \
	            "must fit bofore predict"
	        #新向量的维数，与原矩阵相同
	        assert X_predict.shape[1] == self._X_train.shape[1], \
	            "the feature number of X_predict must be equal to X_train"
	        #预测多个新的特征点
	        y_predict = [self._predict(x) for x in X_predict]
	        return np.array(y_predict)
	    #单个预测
	    def _predict(self, x):
	        assert x.shape[0] == self._X_train.shape[1], \
	            "the feature number of x must be equal to X_train"
	        distances = [sqrt(np.sum((x_train - x)**2)) for x_train in self._X_train]
	        nearest = np.argsort(distances)
	        topK_y = [self._y_train[i] for i in nearest[:self.k]]
	        votes = Counter(topK_y)
	        return votes.most_common(1)[0][0]
	    def _repr_(self):
	        return "KNN(k=%d)" % self.k
在jupyter notebook里运行

	#库和数据
	import numpy as np
	import matplotlib.pyplot as plt
	raw_data_X = [[3.393533211, 2.331273381],
	              [3.110073483, 1.781539638],
	              [1.343808831, 3.368360954],
	              [3.582294042, 4.679179110],
	              [2.280362439, 2.866990263],
	              [7.423436942, 4.696522875],
	              [5.745051997, 3.533989803],
	              [9.172168622, 2.511101045],
	              [7.792783481, 3.424088941],
	              [7.939820817, 0.791637231]]
	raw_data_y = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]
	#训练集
	X_train = np.array(raw_data_X)
	y_train = np.array(raw_data_y)
	#新数据
	x = np.array([8.093607318, 3.365731514])
	X_predict = x.reshape(1, -1)
	#导入kNN
	%run D:/zzh/machieLearn/kNN.py
	#初始化
	knn_clf = KNN(k = 6)
	#训练模型
	knn_clf.fit(X_train, y_train)
	#进行预测
	y_predict = knn_clf.predict(X_predict)
